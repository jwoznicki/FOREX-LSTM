{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Put the time series data into a special class for visualization and data preparation\n",
    "import LSTM\n",
    "from utils import Quandl\n",
    "\n",
    "# Set some settings for the notebook\n",
    "pd.options.display.max_columns = 999\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in the currency data\n",
    "df_dict = Quandl.load_forex_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "features = []#['SandP','TBill','BollingerLower','BollingerMiddle','BollingerUpper','RSI','MA10','EMA12','EMA26','MACD']\n",
    "targets = ['Value']\n",
    "\n",
    "# Data hyperparams\n",
    "time_steps = 365 # How far back are we looking?\n",
    "test_size = 0.2\n",
    "\n",
    "# LSTM hyperparams\n",
    "hidden_size = 10 # How many outputs from the LSTM layer itself, which will then pass thorugh a linear layer?\n",
    "num_layers = 1 # How many LSTM layers?\n",
    "dropout = 0.0 # If we have multiple layers, what rate are we applying dropout?\n",
    "\n",
    "# Training hyperparams\n",
    "num_epochs = 2000\n",
    "loss = 'MAE' # MAE\n",
    "optimizer = 'Adam' # SGD, RMSProp\n",
    "\n",
    "lr = 0.001 # learning Rate\n",
    "# Momentum\n",
    "weight_decay = 0.0 # weight decay (Regularization)\n",
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each data, load and manipulate the data, then train an lstm\n",
    "for curr in df_dict:\n",
    "    print('Predicting '+curr+', daily')\n",
    "    print('')\n",
    "    data = df_dict[curr].copy()\n",
    "\n",
    "    # Create a new LSTM data model to begin\n",
    "    lstmModel = LSTM.LSTM(data=data, name=curr, time_len='daily')\n",
    "    # Load the model\n",
    "    lstmModel.load(features=features, targets=targets, test_size=test_size, time_steps=time_steps)\n",
    "    lstmModel.create(hidden_size, num_layers, dropout)\n",
    "    lstmModel.train(loss, optimizer, num_epochs, lr, weight_decay)\n",
    "    lstmModel.visualize_train()\n",
    "    lstmModel.visualize_error()\n",
    "\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting AUS, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:17:06.748876\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 1.0582822561264038, Validation Loss: 0.9344905614852905\n",
      "Epoch 250, Train Loss: 0.39029714093107, Validation Loss: 0.3677851241898252\n",
      "Epoch 499, Train Loss: 0.24277172107001146, Validation Loss: 0.24347306944429875\n",
      "Training completed at 2019-04-28 21:17:19.479723, taking: 12.730847 seconds. Test error: 0.1139349564909935 (vs baseline: 0.4383615553379059)\n",
      "\n",
      "\n",
      "\n",
      "Predicting CAD, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:17:21.467353\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 0.982248326142629, Validation Loss: 0.976020097732544\n",
      "Epoch 250, Train Loss: 0.40286983717801883, Validation Loss: 0.36441444350310054\n",
      "Epoch 499, Train Loss: 0.24444253457834325, Validation Loss: 0.22420657202601432\n",
      "Training completed at 2019-04-28 21:17:34.578147, taking: 13.110794 seconds. Test error: 0.08004167675971985 (vs baseline: 0.4081822633743286)\n",
      "\n",
      "\n",
      "\n",
      "Predicting JPY, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:17:36.652576\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 0.974874754746755, Validation Loss: 0.8449293971061707\n",
      "Epoch 250, Train Loss: 0.29670964583141074, Validation Loss: 0.24071864510674876\n",
      "Epoch 499, Train Loss: 0.20456986664732296, Validation Loss: 0.16439435255527496\n",
      "Training completed at 2019-04-28 21:17:49.659682, taking: 13.007106 seconds. Test error: 0.12166959047317505 (vs baseline: 0.2723158895969391)\n",
      "\n",
      "\n",
      "\n",
      "Predicting GBP, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:17:51.694185\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 0.9908380508422852, Validation Loss: 0.7690363526344299\n",
      "Epoch 250, Train Loss: 0.4865972307692486, Validation Loss: 0.3540098104343946\n",
      "Epoch 499, Train Loss: 0.33846748413145544, Validation Loss: 0.2829964399933815\n",
      "Training completed at 2019-04-28 21:18:04.630447, taking: 12.936262 seconds. Test error: 0.40815994143486023 (vs baseline: 0.7834954261779785)\n",
      "\n",
      "\n",
      "\n",
      "Predicting ZAR, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:18:06.813585\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 1.1163103183110554, Validation Loss: 0.9466506242752075\n",
      "Epoch 250, Train Loss: 0.3437796458700897, Validation Loss: 0.26632237527890507\n",
      "Epoch 499, Train Loss: 0.2041646212823689, Validation Loss: 0.1517663895227015\n",
      "Training completed at 2019-04-28 21:18:19.479573, taking: 12.665988 seconds. Test error: 0.058195389807224274 (vs baseline: 0.30056634545326233)\n",
      "\n",
      "\n",
      "\n",
      "Predicting CHF, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:18:21.613842\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 1.0207653045654297, Validation Loss: 0.9008913040161133\n",
      "Epoch 250, Train Loss: 0.3489297027211107, Validation Loss: 0.3174342202594081\n",
      "Epoch 499, Train Loss: 0.23257190070052944, Validation Loss: 0.21044793090224265\n",
      "Training completed at 2019-04-28 21:18:34.813430, taking: 13.199588 seconds. Test error: 0.0803111344575882 (vs baseline: 0.36555740237236023)\n",
      "\n",
      "\n",
      "\n",
      "Predicting EUR, monthly\n",
      "\n",
      "\n",
      "Data prepared:\n",
      "    Number of Features: 1\n",
      "    Number of Outputs: 1\n",
      "    Lookback 12 time steps\n",
      "\n",
      "Model:\n",
      "    1-layer LSTM with feed-forward linear output from 10 hidden nodes.\n",
      "\n",
      "Training Model for 500 epochs - start time: 2019-04-28 21:18:37.000526\n",
      "    Optimized using Adam, learning rate: 0.001\n",
      "    Loss calculated with MAE\n",
      "\n",
      "Epoch 0, Train Loss: 1.0250035325686138, Validation Loss: 1.1243358850479126\n",
      "Epoch 250, Train Loss: 0.38693838097540983, Validation Loss: 0.4058036627285034\n",
      "Epoch 499, Train Loss: 0.23543201071023942, Validation Loss: 0.2687499915212393\n",
      "Training completed at 2019-04-28 21:18:49.903876, taking: 12.90335 seconds. Test error: 0.14595335721969604 (vs baseline: 0.424247682094574)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data hyperparams\n",
    "time_steps = 12 # How far back are we looking?\n",
    "# Training hyperparams\n",
    "num_epochs = 500\n",
    "\n",
    "# For each data, load and manipulate the data, then train an lstm\n",
    "for curr in df_dict:\n",
    "    print('Predicting '+curr+', monthly')\n",
    "    print('')\n",
    "    data = df_dict[curr].copy()\n",
    "    \n",
    "    data['month'] = data.index.month\n",
    "    data['year'] = data.index.year\n",
    "    data.reset_index(inplace=True)\n",
    "    data = data.loc[data.groupby(by=('month','year'))['Date'].idxmin()]\n",
    "\n",
    "    # Create a new LSTM data model to begin\n",
    "    lstmModel = LSTM.LSTM(data=data, name=curr, time_len='monthly')\n",
    "    # Load the model\n",
    "    lstmModel.load(features=features, targets=targets, test_size=test_size, time_steps=time_steps)\n",
    "    lstmModel.create(hidden_size, num_layers, dropout)\n",
    "    lstmModel.train(loss, optimizer, num_epochs)\n",
    "    lstmModel.visualize_train()\n",
    "    lstmModel.visualize_error()\n",
    "\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1975-01-02</th>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-03</th>\n",
       "      <td>0.7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-06</th>\n",
       "      <td>0.7537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-07</th>\n",
       "      <td>0.7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-08</th>\n",
       "      <td>0.7520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Value\n",
       "Date              \n",
       "1975-01-02  0.7540\n",
       "1975-01-03  0.7552\n",
       "1975-01-06  0.7537\n",
       "1975-01-07  0.7518\n",
       "1975-01-08  0.7520"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['AUS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "features = []#['SandP','TBill','BollingerLower','BollingerMiddle','BollingerUpper','RSI','MA10','EMA12','EMA26','MACD']\n",
    "targets = ['Value']\n",
    "\n",
    "# Data hyperparams\n",
    "time_steps = 365 # How far back are we looking?\n",
    "test_size = 0.2\n",
    "\n",
    "# LSTM hyperparams\n",
    "hidden_size = 10 # How many outputs from the LSTM layer itself, which will then pass thorugh a linear layer?\n",
    "num_layers = 1 # How many LSTM layers?\n",
    "dropout = 0.0 # If we have multiple layers, what rate are we applying dropout?\n",
    "\n",
    "# Training hyperparams\n",
    "num_epochs = 100\n",
    "loss = 'MAE' # MAE\n",
    "optimizer = 'AdamW' # SGD, RMSProp\n",
    "\n",
    "lr = 0.001 # learning Rate\n",
    "# Momentum\n",
    "weight_decay = 0.0 # weight decay (Regularization)\n",
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "1) compare to ARIMA, NARX\n",
    "\n",
    "3) Add in KFIs\n",
    "    - Highs/Lows\n",
    "    - Volume\n",
    "    - Interest\n",
    "    - Strength\n",
    "    - Stochastic Oscillation\n",
    "    - %R (Overbought/sold)\n",
    "    - MACD\n",
    "    - Price Rate of change\n",
    "    - DMA (50MA - 10MA)\n",
    "    - Volatility Volume ratio\n",
    "    - Moving averages\n",
    "    \n",
    "4) EDA\n",
    "    - What can we learn from the plots?\n",
    "    - Show the effect of transformations\n",
    "    \n",
    "5) Hyperparameter optimization\n",
    "    - What hyperparams?\n",
    "    \n",
    "6) Build out look forward!\n",
    "\n",
    "7) Add in refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
